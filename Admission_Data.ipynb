{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnTs+rPfmXKGQ7pyXdK812",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameympatil/Pytorch/blob/main/Admission_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch implementation"
      ],
      "metadata": {
        "id": "W3VcujEEaD5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Admission Prediction"
      ],
      "metadata": {
        "id": "mFRKcIXAonFI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP0KzD7KPa2h"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.5\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kagglesdsdata/datasets/14872/228180/Admission_Predict_Ver1.1.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230315%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230315T193003Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=731646df7449c30b695ffdf4da67337812a9e9ab8e16d0d2af3d98cc0b98637e37ab59c0946483acad9323cc34dcd745193bc00035b8c0a56f42bac845b96720ac0a61c16a5ab644e3ad0e9ee860fef58ad145d0d1c0cd8b5521a74b86981a6057d514fd0cb13a63ed8467f083aa91e9b998d3fcea3732e5ab52c84ffa1c32636203883cad96b2c4640cd46afa9f578dfedb73074095d269e30523bcca66ef9ae28161fc78c3b68c19bde5caddbeb4f956e27e6e702fae118121ea6113890d0cf8d6a2dc70a017c824ca8ae2963604b66da8543ed13708423ac0d24e96fd90e82e04641be2f27fa10171798e2bc62e61e7385d56f6c2b6a20b1aa4a0fde95bdc\" -c -O 'Admission_Predict_Ver1.1.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44wgYQUjSYG6",
        "outputId": "5f4e82ce-3302-4ae6-ef3b-7e60615b4445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-15 20:14:05--  https://storage.googleapis.com/kagglesdsdata/datasets/14872/228180/Admission_Predict_Ver1.1.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230315%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230315T193003Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=731646df7449c30b695ffdf4da67337812a9e9ab8e16d0d2af3d98cc0b98637e37ab59c0946483acad9323cc34dcd745193bc00035b8c0a56f42bac845b96720ac0a61c16a5ab644e3ad0e9ee860fef58ad145d0d1c0cd8b5521a74b86981a6057d514fd0cb13a63ed8467f083aa91e9b998d3fcea3732e5ab52c84ffa1c32636203883cad96b2c4640cd46afa9f578dfedb73074095d269e30523bcca66ef9ae28161fc78c3b68c19bde5caddbeb4f956e27e6e702fae118121ea6113890d0cf8d6a2dc70a017c824ca8ae2963604b66da8543ed13708423ac0d24e96fd90e82e04641be2f27fa10171798e2bc62e61e7385d56f6c2b6a20b1aa4a0fde95bdc\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.112.128, 74.125.124.128, 172.217.212.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.112.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested range not satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset includes various information like GRE score, TOEFL score, university rating, SOP (Statement of Purpose), LOR (Letter of Recommendation), CGPA, research and chance of admit. In this dataset, 400 entries are included.\n",
        "\n",
        "GRE Scores ( out of 340 ) \\\n",
        "TOEFL Scores ( out of 120 ) \\\n",
        "University Rating ( out of 5 ) \\\n",
        "Statement of Purpose (SOP) and Letter of Recommendation (LOR) Strength ( out of 5 ) \\\n",
        "Undergraduate GPA ( out of 10 ) \\\n",
        "Research Experience ( either 0 or 1 ) \\\n",
        "Chance of Admit ( ranging from 0 to 1 )."
      ],
      "metadata": {
        "id": "eIYMXQGkYfmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Admission_Predict_Ver1.1.csv')"
      ],
      "metadata": {
        "id": "by3ciPM9SY9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "kDg_x8CJSk3H",
        "outputId": "5179e402-eb8b-46dc-b0d7-f6cced609c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
              "0           1        337          118                  4  4.5   4.5  9.65   \n",
              "1           2        324          107                  4  4.0   4.5  8.87   \n",
              "2           3        316          104                  3  3.0   3.5  8.00   \n",
              "3           4        322          110                  3  3.5   2.5  8.67   \n",
              "4           5        314          103                  2  2.0   3.0  8.21   \n",
              "\n",
              "   Research  Chance of Admit   \n",
              "0         1              0.92  \n",
              "1         1              0.76  \n",
              "2         1              0.72  \n",
              "3         1              0.80  \n",
              "4         0              0.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b3d5d6c-f241-4046-93fe-06532bab8908\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b3d5d6c-f241-4046-93fe-06532bab8908')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b3d5d6c-f241-4046-93fe-06532bab8908 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b3d5d6c-f241-4046-93fe-06532bab8908');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Serial No.'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "a78k9GtHYHEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DeaRXm6vncb",
        "outputId": "5632f157-011b-4e52-b244-d10fc9d7363f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "8ii8VhkfZMZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "FOF4QmdhZpl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "bAyQ391qw25R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to Tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test  = torch.FloatTensor(X_test)\n",
        "y_train = torch.FloatTensor(y_train.values)\n",
        "y_test = torch.FloatTensor(y_test.values)"
      ],
      "metadata": {
        "id": "4AuExRu-auxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Building\n",
        "class ANN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(X_train.shape[1],7)\n",
        "    self.fc2 = nn.Linear(7,7)\n",
        "    self.fc3 = nn.Linear(7,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ABufYyHEb4cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ANN()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwwkBrkCdPIA",
        "outputId": "f19f6bfc-70f7-40af-a9b7-5e14b9a3b445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN(\n",
            "  (fc1): Linear(in_features=7, out_features=7, bias=True)\n",
            "  (fc2): Linear(in_features=7, out_features=7, bias=True)\n",
            "  (fc3): Linear(in_features=7, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Backward Propogation --> Loss function , Optimizer\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "KS3crtXvdYvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "final_loss = []\n",
        "for i in range(epochs):\n",
        "  i = i +1\n",
        "\n",
        "  # forward propogation\n",
        "  y_pred = model.forward(X_train)\n",
        "\n",
        "  # Calculating loss\n",
        "  loss = loss_function(y_pred,y_train)\n",
        "  final_loss.append(loss)\n",
        "  print(\"Epoch: {} Loss: {}\".format(i,loss.item()))\n",
        "\n",
        "  # Zero all gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Computing the gradients of the loss w.r.t the model parameters.\n",
        "  loss.backward()\n",
        "\n",
        "  # Updating Model parametres\n",
        "  optimizer.step()\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puoZHW8BeatO",
        "outputId": "6be039fb-7950-45c5-fc1c-789783b213f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss: 0.4408770501613617\n",
            "Epoch: 2 Loss: 0.4345577657222748\n",
            "Epoch: 3 Loss: 0.4282819926738739\n",
            "Epoch: 4 Loss: 0.4220500588417053\n",
            "Epoch: 5 Loss: 0.4158604145050049\n",
            "Epoch: 6 Loss: 0.4097138047218323\n",
            "Epoch: 7 Loss: 0.40361306071281433\n",
            "Epoch: 8 Loss: 0.3975551128387451\n",
            "Epoch: 9 Loss: 0.3915415108203888\n",
            "Epoch: 10 Loss: 0.3855718970298767\n",
            "Epoch: 11 Loss: 0.37964656949043274\n",
            "Epoch: 12 Loss: 0.3737647831439972\n",
            "Epoch: 13 Loss: 0.36792418360710144\n",
            "Epoch: 14 Loss: 0.3621223270893097\n",
            "Epoch: 15 Loss: 0.35636091232299805\n",
            "Epoch: 16 Loss: 0.3506346046924591\n",
            "Epoch: 17 Loss: 0.34494253993034363\n",
            "Epoch: 18 Loss: 0.3392851948738098\n",
            "Epoch: 19 Loss: 0.3336614966392517\n",
            "Epoch: 20 Loss: 0.3280693590641022\n",
            "Epoch: 21 Loss: 0.32250654697418213\n",
            "Epoch: 22 Loss: 0.3169744908809662\n",
            "Epoch: 23 Loss: 0.31147143244743347\n",
            "Epoch: 24 Loss: 0.3059937655925751\n",
            "Epoch: 25 Loss: 0.30054256319999695\n",
            "Epoch: 26 Loss: 0.29511332511901855\n",
            "Epoch: 27 Loss: 0.2897043824195862\n",
            "Epoch: 28 Loss: 0.2843148410320282\n",
            "Epoch: 29 Loss: 0.27894482016563416\n",
            "Epoch: 30 Loss: 0.273593544960022\n",
            "Epoch: 31 Loss: 0.2682601511478424\n",
            "Epoch: 32 Loss: 0.26294228434562683\n",
            "Epoch: 33 Loss: 0.2576393187046051\n",
            "Epoch: 34 Loss: 0.2523525357246399\n",
            "Epoch: 35 Loss: 0.24708151817321777\n",
            "Epoch: 36 Loss: 0.24182748794555664\n",
            "Epoch: 37 Loss: 0.23659084737300873\n",
            "Epoch: 38 Loss: 0.23137368261814117\n",
            "Epoch: 39 Loss: 0.2261756807565689\n",
            "Epoch: 40 Loss: 0.2209981381893158\n",
            "Epoch: 41 Loss: 0.2158432900905609\n",
            "Epoch: 42 Loss: 0.2107132524251938\n",
            "Epoch: 43 Loss: 0.20560923218727112\n",
            "Epoch: 44 Loss: 0.20053012669086456\n",
            "Epoch: 45 Loss: 0.19548051059246063\n",
            "Epoch: 46 Loss: 0.19046251475811005\n",
            "Epoch: 47 Loss: 0.18547788262367249\n",
            "Epoch: 48 Loss: 0.1805315613746643\n",
            "Epoch: 49 Loss: 0.17562544345855713\n",
            "Epoch: 50 Loss: 0.17076221108436584\n",
            "Epoch: 51 Loss: 0.16594618558883667\n",
            "Epoch: 52 Loss: 0.16117893159389496\n",
            "Epoch: 53 Loss: 0.15646593272686005\n",
            "Epoch: 54 Loss: 0.15181154012680054\n",
            "Epoch: 55 Loss: 0.1472182273864746\n",
            "Epoch: 56 Loss: 0.1426902413368225\n",
            "Epoch: 57 Loss: 0.13823112845420837\n",
            "Epoch: 58 Loss: 0.13384485244750977\n",
            "Epoch: 59 Loss: 0.12953491508960724\n",
            "Epoch: 60 Loss: 0.1253049373626709\n",
            "Epoch: 61 Loss: 0.12115830928087234\n",
            "Epoch: 62 Loss: 0.11709849536418915\n",
            "Epoch: 63 Loss: 0.1131289079785347\n",
            "Epoch: 64 Loss: 0.10925287008285522\n",
            "Epoch: 65 Loss: 0.10547362267971039\n",
            "Epoch: 66 Loss: 0.10179418325424194\n",
            "Epoch: 67 Loss: 0.09821759164333344\n",
            "Epoch: 68 Loss: 0.09474657475948334\n",
            "Epoch: 69 Loss: 0.0913836658000946\n",
            "Epoch: 70 Loss: 0.08813111484050751\n",
            "Epoch: 71 Loss: 0.08499133586883545\n",
            "Epoch: 72 Loss: 0.08196616917848587\n",
            "Epoch: 73 Loss: 0.07905758917331696\n",
            "Epoch: 74 Loss: 0.07626701891422272\n",
            "Epoch: 75 Loss: 0.07359551638364792\n",
            "Epoch: 76 Loss: 0.07104402035474777\n",
            "Epoch: 77 Loss: 0.06861308217048645\n",
            "Epoch: 78 Loss: 0.06630279123783112\n",
            "Epoch: 79 Loss: 0.06411312520503998\n",
            "Epoch: 80 Loss: 0.06204353645443916\n",
            "Epoch: 81 Loss: 0.06009291484951973\n",
            "Epoch: 82 Loss: 0.05826010927557945\n",
            "Epoch: 83 Loss: 0.05654359608888626\n",
            "Epoch: 84 Loss: 0.05494146794080734\n",
            "Epoch: 85 Loss: 0.053451329469680786\n",
            "Epoch: 86 Loss: 0.05207051336765289\n",
            "Epoch: 87 Loss: 0.0507960245013237\n",
            "Epoch: 88 Loss: 0.04962443932890892\n",
            "Epoch: 89 Loss: 0.048552077263593674\n",
            "Epoch: 90 Loss: 0.047574885189533234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 91 Loss: 0.046688511967659\n",
            "Epoch: 92 Loss: 0.045888468623161316\n",
            "Epoch: 93 Loss: 0.045169930905103683\n",
            "Epoch: 94 Loss: 0.04452797397971153\n",
            "Epoch: 95 Loss: 0.04395776614546776\n",
            "Epoch: 96 Loss: 0.04345409572124481\n",
            "Epoch: 97 Loss: 0.043011732399463654\n",
            "Epoch: 98 Loss: 0.04262540116906166\n",
            "Epoch: 99 Loss: 0.0422900952398777\n",
            "Epoch: 100 Loss: 0.042000818997621536\n",
            "Epoch: 101 Loss: 0.04175269603729248\n",
            "Epoch: 102 Loss: 0.04154089465737343\n",
            "Epoch: 103 Loss: 0.041360873728990555\n",
            "Epoch: 104 Loss: 0.04120838642120361\n",
            "Epoch: 105 Loss: 0.041079435497522354\n",
            "Epoch: 106 Loss: 0.040970295667648315\n",
            "Epoch: 107 Loss: 0.04087744653224945\n",
            "Epoch: 108 Loss: 0.04079780727624893\n",
            "Epoch: 109 Loss: 0.040728624910116196\n",
            "Epoch: 110 Loss: 0.04066742956638336\n",
            "Epoch: 111 Loss: 0.04061203449964523\n",
            "Epoch: 112 Loss: 0.040560588240623474\n",
            "Epoch: 113 Loss: 0.04051150381565094\n",
            "Epoch: 114 Loss: 0.04046350345015526\n",
            "Epoch: 115 Loss: 0.04041554778814316\n",
            "Epoch: 116 Loss: 0.04036680981516838\n",
            "Epoch: 117 Loss: 0.04031665623188019\n",
            "Epoch: 118 Loss: 0.04026465117931366\n",
            "Epoch: 119 Loss: 0.04021052271127701\n",
            "Epoch: 120 Loss: 0.0401541031897068\n",
            "Epoch: 121 Loss: 0.04009536653757095\n",
            "Epoch: 122 Loss: 0.040034376084804535\n",
            "Epoch: 123 Loss: 0.039971232414245605\n",
            "Epoch: 124 Loss: 0.039906129240989685\n",
            "Epoch: 125 Loss: 0.03983927145600319\n",
            "Epoch: 126 Loss: 0.03977091237902641\n",
            "Epoch: 127 Loss: 0.039701275527477264\n",
            "Epoch: 128 Loss: 0.039630644023418427\n",
            "Epoch: 129 Loss: 0.03955933451652527\n",
            "Epoch: 130 Loss: 0.039487551897764206\n",
            "Epoch: 131 Loss: 0.03941551223397255\n",
            "Epoch: 132 Loss: 0.03934335708618164\n",
            "Epoch: 133 Loss: 0.03927125036716461\n",
            "Epoch: 134 Loss: 0.039199333637952805\n",
            "Epoch: 135 Loss: 0.03912775591015816\n",
            "Epoch: 136 Loss: 0.03905659541487694\n",
            "Epoch: 137 Loss: 0.038985926657915115\n",
            "Epoch: 138 Loss: 0.03891586884856224\n",
            "Epoch: 139 Loss: 0.038846392184495926\n",
            "Epoch: 140 Loss: 0.03877752274274826\n",
            "Epoch: 141 Loss: 0.03870926424860954\n",
            "Epoch: 142 Loss: 0.03864156827330589\n",
            "Epoch: 143 Loss: 0.03857440501451492\n",
            "Epoch: 144 Loss: 0.03850774094462395\n",
            "Epoch: 145 Loss: 0.03844153881072998\n",
            "Epoch: 146 Loss: 0.038375772535800934\n",
            "Epoch: 147 Loss: 0.038310397416353226\n",
            "Epoch: 148 Loss: 0.038245365023612976\n",
            "Epoch: 149 Loss: 0.03818066418170929\n",
            "Epoch: 150 Loss: 0.038116250187158585\n",
            "Epoch: 151 Loss: 0.03805205598473549\n",
            "Epoch: 152 Loss: 0.037988051772117615\n",
            "Epoch: 153 Loss: 0.03792424872517586\n",
            "Epoch: 154 Loss: 0.03786063939332962\n",
            "Epoch: 155 Loss: 0.037797119468450546\n",
            "Epoch: 156 Loss: 0.037733666598796844\n",
            "Epoch: 157 Loss: 0.037670254707336426\n",
            "Epoch: 158 Loss: 0.037606872618198395\n",
            "Epoch: 159 Loss: 0.03754351660609245\n",
            "Epoch: 160 Loss: 0.03748016431927681\n",
            "Epoch: 161 Loss: 0.03741680458188057\n",
            "Epoch: 162 Loss: 0.03735344856977463\n",
            "Epoch: 163 Loss: 0.03729008883237839\n",
            "Epoch: 164 Loss: 0.03722671419382095\n",
            "Epoch: 165 Loss: 0.037163328379392624\n",
            "Epoch: 166 Loss: 0.03709994629025459\n",
            "Epoch: 167 Loss: 0.03703654184937477\n",
            "Epoch: 168 Loss: 0.036973148584365845\n",
            "Epoch: 169 Loss: 0.03690975904464722\n",
            "Epoch: 170 Loss: 0.036846376955509186\n",
            "Epoch: 171 Loss: 0.03678300604224205\n",
            "Epoch: 172 Loss: 0.036719657480716705\n",
            "Epoch: 173 Loss: 0.036656323820352554\n",
            "Epoch: 174 Loss: 0.03659302368760109\n",
            "Epoch: 175 Loss: 0.036529749631881714\n",
            "Epoch: 176 Loss: 0.036466505378484726\n",
            "Epoch: 177 Loss: 0.03640329837799072\n",
            "Epoch: 178 Loss: 0.0363401360809803\n",
            "Epoch: 179 Loss: 0.03627700358629227\n",
            "Epoch: 180 Loss: 0.03621392324566841\n",
            "Epoch: 181 Loss: 0.03615088015794754\n",
            "Epoch: 182 Loss: 0.03608788549900055\n",
            "Epoch: 183 Loss: 0.03602493181824684\n",
            "Epoch: 184 Loss: 0.03596203401684761\n",
            "Epoch: 185 Loss: 0.03589918091893196\n",
            "Epoch: 186 Loss: 0.03583637252449989\n",
            "Epoch: 187 Loss: 0.035773616284132004\n",
            "Epoch: 188 Loss: 0.0357108972966671\n",
            "Epoch: 189 Loss: 0.03564824163913727\n",
            "Epoch: 190 Loss: 0.03558562323451042\n",
            "Epoch: 191 Loss: 0.03552306070923805\n",
            "Epoch: 192 Loss: 0.035460542887449265\n",
            "Epoch: 193 Loss: 0.03539808467030525\n",
            "Epoch: 194 Loss: 0.03533567488193512\n",
            "Epoch: 195 Loss: 0.035273317247629166\n",
            "Epoch: 196 Loss: 0.03521101176738739\n",
            "Epoch: 197 Loss: 0.035148750990629196\n",
            "Epoch: 198 Loss: 0.03508654609322548\n",
            "Epoch: 199 Loss: 0.035024385899305344\n",
            "Epoch: 200 Loss: 0.034962255507707596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fi_los = [fl.item() for fl in final_loss]"
      ],
      "metadata": {
        "id": "RDgLSdfcfN3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plot Loss function\n",
        "plt.plot(range(epochs),fi_los)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "25H14QPUpl71",
        "outputId": "8f705d82-5ba3-4b93-9e92-75b55d9377ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 376
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test data\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "  for i,data in enumerate(X_test):\n",
        "    y_pred = model(data)\n",
        "    predictions.append(y_pred)"
      ],
      "metadata": {
        "id": "aLaqx-r_pq-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY4mJukeqTXs",
        "outputId": "2254df20-7519-4f50-ae0d-27430535ba2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7452325720761026"
            ]
          },
          "metadata": {},
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ka7Vygw7qUTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}